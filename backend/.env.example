# Supabase Configuration
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_ANON_KEY=your_anon_key_here
SUPABASE_SERVICE_ROLE_KEY=your_service_role_key_here

# Database Configuration
# Using Supabase Session Pooler (IPv4-compatible)
DATABASE_URL=postgresql://postgres.project-ref:password@region.pooler.supabase.com:5432/postgres

# FastAPI Configuration
FASTAPI_SECRET_KEY=your_secret_key_here_minimum_32_characters
FASTAPI_DEBUG=True

# Google Cloud Vision API (Base64 encoded service account JSON)
GOOGLE_VISION_KEY_BASE64=your_base64_encoded_service_account_key

# ============================================================================
# LLM Configuration (Day 11 - Natural Language Intent Parsing)
# ============================================================================

# Enable/Disable LLM parsing (feature flag)
# Set to 'true' to use LLM for natural language parsing
# Set to 'false' to use classic regex parser (Day 7-10 behavior)
USE_LLM_PARSE=true

# LLM Provider Selection
# Options: openai | gemini | ollama
LLM_PROVIDER=gemini

# OpenAI Configuration (if LLM_PROVIDER=openai)
OPENAI_API_KEY=sk-proj-your_openai_api_key_here
# Recommended models: gpt-4o-mini, gpt-4o, gpt-4-turbo

# Google Gemini Configuration (if LLM_PROVIDER=gemini)
GEMINI_API_KEY=your_gemini_api_key_here
# Available models: gemini-2.5-flash, gemini-2.5-pro, gemini-2.0-flash
# Run 'python list_gemini_models.py' to see all available models

# Ollama Configuration (if LLM_PROVIDER=ollama)
OLLAMA_BASE_URL=http://localhost:11434
# Recommended models: llama2, mistral, codellama

# LLM Model Name
# For OpenAI: gpt-4o-mini (default), gpt-4o, gpt-4-turbo
# For Gemini: gemini-2.5-flash (default), gemini-2.5-pro
# For Ollama: llama2, mistral, etc.
LLM_MODEL=gemini-2.5-flash

# LLM Request Timeout (seconds)
# Maximum time to wait for LLM response before falling back to clarification
LLM_TIMEOUT_SECONDS=10

# ============================================================================
# Production Deployment Configuration
# ============================================================================

# CORS Origins (comma-separated list of allowed frontend URLs)
# Example: https://movi-app.vercel.app,https://preview.movi-app.vercel.app
CORS_ORIGINS=

# ============================================================================
# LLM Integration Features (Automatically Enabled with USE_LLM_PARSE=true)
# ============================================================================
# ✅ Natural language command parsing
# ✅ Intent extraction with confidence scoring
# ✅ Automatic trip identification from descriptions
# ✅ Smart clarification when ambiguous
# ✅ DB verification of all LLM suggestions
# ✅ OCR bypass (selectedTripId skips LLM)
# ✅ Explanation generation for user feedback
# ✅ Fallback to classic parser if LLM fails
# ✅ Audit trail of LLM reasoning
# ============================================================================
